{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4357d80-362f-4a9d-8784-a5e236c62cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "500fd511-eb21-4a6d-9144-ea0bc69191e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foreground.png'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove():\n",
    "    board_path = \"Assignment/data/BOARDS/\"\n",
    "    # Load the image\n",
    "    image_path = 'Assignment/data/BOARDS/BOARD2-1.jpg'\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply a binary threshold to get a binary image\n",
    "    # You may need to adjust the threshold value based on your image's lighting conditions\n",
    "    _, binary = cv2.threshold(gray, 160, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Find contours which will detect the foreground objects\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create an all black image with the same dimensions as the loaded image\n",
    "    mask = np.zeros_like(binary)\n",
    "    \n",
    "    # Draw the contours on the mask with white color\n",
    "    cv2.drawContours(mask, contours, -1, (255), thickness=cv2.FILLED)\n",
    "    \n",
    "    # Bitwise the mask with the original image to extract the foreground\n",
    "    foreground = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Save the foreground image\n",
    "    output = 'foreground.png'\n",
    "    cv2.imwrite(output, foreground)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1cf8b5-0ef9-4f6b-aeb7-f203a2eed9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "board_path = \"Assignment/data/BOARDS/\"\n",
    "\n",
    "image_paths = []\n",
    "images = []\n",
    "images_grey = []\n",
    "for i in range(3):\n",
    "    index = str(i + 1)\n",
    "    board_path_i = []\n",
    "    image = []\n",
    "    image_grey = []\n",
    "    for j in range(3):\n",
    "        jedex = str(j + 1)\n",
    "        path = board_path+'BOARD'+index+'-'+jedex+'.jpg'\n",
    "        input_path = path\n",
    "        output_path = 'BOARD'+index+'-'+jedex+'.jpg'\n",
    "        with open(input_path, 'rb') as i:\n",
    "            with open(output_path, 'wb') as o:\n",
    "                input = i.read()\n",
    "                output = remove(input)\n",
    "                o.write(output)\n",
    "        path = output_path\n",
    "        board_path_i.append(path)\n",
    "        im = cv2.imread(path)\n",
    "        image.append(im)\n",
    "        grey = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        image_grey.append(grey)\n",
    "    image_paths.append(board_path_i)\n",
    "    images.append(image)\n",
    "    images_grey.append(image_grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30864db0-6ac8-447c-8446-f5659508c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to align images based on ORB features\n",
    "def align_images(base_image, align_image):\n",
    "    # Initialize ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "    # Find the keypoints and descriptors with ORB\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(base_image, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(align_image, None)\n",
    "\n",
    "    # Create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    # Sort them in the order of their distance\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "    # Find homography\n",
    "    h, mask = cv2.findHomography(points2, points1, cv2.RANSAC)\n",
    "\n",
    "    # Use homography to warp image\n",
    "    height, width = base_image.shape\n",
    "    aligned_image = cv2.warpPerspective(align_image, h, (width, height))\n",
    "    \n",
    "    return aligned_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599db57-ded0-4436-b2ed-67fd76b33305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aligned_them(im1, im2, boardnum, imagenum):\n",
    "    aligned = align_images(im1, im2)\n",
    "    plt.imshow(aligned, cmap='gray')\n",
    "    plt.title('Aligned BOARD'+str(boardnum)+' Image '+str(imagenum))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4c0ad-9c34-4b4b-bb79-5a6d7e030b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_b1_image2 = aligned_them(images_grey[0][0],images_grey[0][1],1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079717ac-edaf-40bb-8a70-8ef15bfd7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_b1_image3 = aligned_them(images_grey[0][0],images_grey[0][2],1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc77ee5-49ea-483b-8f6e-42d1cca38d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_b2_image2 = aligned_them(images_grey[1][0],images_grey[1][1],2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49a283-8e99-4fd8-b575-dbd998cf2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_b2_image3 = aligned_them(images_grey[1][0],images_grey[1][2],2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48327509-21b4-4eb8-9947-6325dd72d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_b3_image2 = aligned_them(images_grey[2][0],images_grey[2][1],3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c8782-ad26-4314-9658-42b66ebe7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_b3_image3 = aligned_them(images_grey[2][0],images_grey[2][2],3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01947bb0-ee72-47ef-99c2-082d05ba1bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_aligned = []\n",
    "img_b1_aligned = [images_grey[0][0],aligned_b1_image2,aligned_b1_image3]\n",
    "img_b2_aligned = [images_grey[1][0],aligned_b2_image2,aligned_b2_image3]\n",
    "img_b3_aligned = [images_grey[2][0],aligned_b3_image2,aligned_b3_image3]\n",
    "img_aligned.append(img_b1_aligned)\n",
    "img_aligned.append(img_b2_aligned)\n",
    "img_aligned.append(img_b3_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd222c-2444-418f-935d-fff25cfdc636",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(img_aligned)):\n",
    "    for j in range(len(img_aligned[i])):\n",
    "        cv2.imwrite(str(i)+str(j)+\".png\", img_aligned[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c66fef-e139-4aa8-b1df-386561eb3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the two images by blending them together with equal weight\n",
    "def average_images(img1, img2):\n",
    "    \"\"\"\n",
    "    This function takes two images, converts them to the same size and mode if necessary,\n",
    "    and returns a new image that is the average of the two.\n",
    "    \"\"\"\n",
    "    # Ensure both images are the same size\n",
    "    img1 = img1.resize(img2.size, Image.LANCZOS)\n",
    "\n",
    "    # Ensure both images are in the same mode\n",
    "    if img1.mode != img2.mode:\n",
    "        img1 = img1.convert(img2.mode)\n",
    "\n",
    "    # Blend the images together with equal weight to both\n",
    "    return Image.blend(img1, img2, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474fdff5-759b-434b-a56b-b1e9c60a4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images again to ensure we're working with the original data\n",
    "image1 = Image.open('00.png')\n",
    "image2 = Image.open('01.png')\n",
    "image3 = Image.open('02.png')\n",
    "\n",
    "# Average the images\n",
    "average_image = average_images(image2, image1)\n",
    "average_image = average_images(average_image, image3)\n",
    "# Save the averaged image\n",
    "average_image_path = 'b1_averaged_image.png'\n",
    "average_image.save(average_image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564e926-fbe3-49e9-a7b2-6bbbed06a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images again to ensure we're working with the original data\n",
    "image1 = Image.open('10.png')\n",
    "image2 = Image.open('11.png')\n",
    "image3 = Image.open('12.png')\n",
    "\n",
    "# Average the images\n",
    "average_image = average_images(image2, image1)\n",
    "average_image = average_images(average_image, image3)\n",
    "# Save the averaged image\n",
    "average_image_path = 'b2_averaged_image.png'\n",
    "average_image.save(average_image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ae794-f6c7-4078-ad39-51ac486f243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images again to ensure we're working with the original data\n",
    "image1 = Image.open('20.png')\n",
    "image2 = Image.open('21.png')\n",
    "image3 = Image.open('22.png')\n",
    "\n",
    "# Average the images\n",
    "average_image = average_images(image2, image1)\n",
    "# average_image = average_images(average_image, image1)\n",
    "# Save the averaged image\n",
    "average_image_path = 'b3_averaged_image.png'\n",
    "average_image.save(average_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af494ce-a1a5-4eac-8b74-0ad1a965bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'b2_averaged_image.png'\n",
    "im = cv2.imread(path)\n",
    "grey2 = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "path = 'b3_averaged_image.png'\n",
    "im = cv2.imread(path)\n",
    "grey3 = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "aligned_b3_to_b2 = align_images(grey2, grey3)\n",
    "\n",
    "plt.imshow(aligned_b3_to_b2, cmap='gray')\n",
    "plt.title('Aligned b3 to b2')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "cv2.imwrite(\"b3_avg_aligned.png\", aligned_b3_to_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b76433-c247-41c7-84b3-8d334a927c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the images\n",
    "base_image_path = 'b2_averaged_image.png'\n",
    "align_image_path = 'b1_averaged_image.png'\n",
    "base_image = cv2.imread(base_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "align_image = cv2.imread(align_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if images are loaded correctly\n",
    "if base_image is None or align_image is None:\n",
    "    raise ValueError(\"Could not load the images!\")\n",
    "\n",
    "# Initialize SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "# Find the keypoints and descriptors with SIFT\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(base_image, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(align_image, None)\n",
    "\n",
    "# Create FLANN matcher\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# Match descriptors using KNN\n",
    "matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "# Store all the good matches as per Lowe's ratio test.\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Extract location of good matches\n",
    "points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
    "points2 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(good_matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "# Find homography\n",
    "h, mask = cv2.findHomography(points2, points1, cv2.RANSAC)\n",
    "\n",
    "# Use homography to warp image\n",
    "height, width = base_image.shape\n",
    "aligned_image = cv2.warpPerspective(align_image, h, (width, height))\n",
    "\n",
    "# Save the aligned image\n",
    "aligned_image_path = 'b1_avg_aligned.png'\n",
    "cv2.imwrite(aligned_image_path, aligned_image)\n",
    "\n",
    "# Display the aligned image\n",
    "plt.imshow(aligned_image, cmap='gray')\n",
    "plt.title('Aligned Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Output the path to the aligned image\n",
    "aligned_image_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830c651-fb07-4804-9366-b7accc9148ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "# Load an image\n",
    "image_path = 'b3_avg_aligned.png'  # Replace with the path to your image\n",
    "image = imread(image_path)\n",
    "\n",
    "# Determine the number of channels\n",
    "if image.ndim == 2:\n",
    "    channels = 1  # Grayscale image\n",
    "elif image.shape[2] == 3:\n",
    "    channels = 3  # RGB image\n",
    "elif image.shape[2] == 4:\n",
    "    channels = 4  # RGBA image\n",
    "\n",
    "print(f\"The image has {channels} channels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44418e76-e905-44b7-8db1-be44055e11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology, measure\n",
    "from scipy.ndimage import label\n",
    "# 假设b1、b2、b3图像已经正确加载到变量b1_img、b2_img、b3_img中。\n",
    "\n",
    "# 计算b3和b2之间的差异，即寻找在b3中但不在b2中的元素\n",
    "diff_b3_b2 = np.abs(b3_img_float - b2_img_float)\n",
    "\n",
    "# 计算b2和b1之间的差异，即b2与空白板之间的不同\n",
    "diff_b2_b1 = np.abs(b2_img_float - b1_img_float)\n",
    "\n",
    "# 修正b3和b2之间的差异，减去b2和b1之间的差异\n",
    "# 这样做的目的是只保留b3中独有的元素，而忽略b2中已有的元素\n",
    "diff_corrected = diff_b3_b2 - diff_b2_b1\n",
    "\n",
    "# 阈值化修正后的差异图像\n",
    "threshold_value = np.max(diff_corrected) * 0.05  # 设定阈值为最大差异的5%\n",
    "diff_thresholded = diff_corrected > threshold_value\n",
    "\n",
    "# 应用形态学开运算来移除小对象\n",
    "selem = morphology.square(3)  # 创建一个3x3的结构元素\n",
    "diff_thresholded_opened = morphology.opening(diff_thresholded, selem)\n",
    "\n",
    "# 应用形态学闭运算来突出显示连续区域\n",
    "selem = morphology.rectangle(5, 5)  # 创建一个5x5的矩形结构元素\n",
    "diff_thresholded_closed = morphology.closing(diff_thresholded_opened, selem)\n",
    "\n",
    "# 使用连通组件分析来识别大面积的差异\n",
    "labeled_array, num_features = label(diff_thresholded_closed)\n",
    "object_areas = [np.sum(labeled_array == i) for i in range(1, num_features + 1)]\n",
    "large_objects = np.isin(labeled_array, [i for i, area in enumerate(object_areas, start=1) if area > 50])  # 假设大于50个像素的为大对象\n",
    "\n",
    "# 准备高亮显示的图像，只包含大的正方形或长方形的零件\n",
    "highlighted_large_objects = np.zeros(b3_img.shape + (3,))\n",
    "highlighted_large_objects[..., 0] = large_objects  # 红色通道表示大的差异\n",
    "highlighted_large_objects[..., 1] = b3_img_float / np.max(b3_img_float)  # 绿色和蓝色通道显示b3板图像\n",
    "highlighted_large_objects[..., 2] = b3_img_float / np.max(b3_img_float)\n",
    "\n",
    "# # 准备高亮显示的图像\n",
    "# highlighted = np.zeros(b3_img.shape + (3,))\n",
    "# highlighted[..., 0] = diff_thresholded  # 红色通道表示差异\n",
    "# highlighted[..., 1] = b3_img_float / np.max(b3_img_float)  # 绿色和蓝色通道显示b3板图像\n",
    "# highlighted[..., 2] = b3_img_float / np.max(b3_img_float)\n",
    "\n",
    "# 显示图像\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "axes[0].imshow(b1_img, cmap='gray')\n",
    "axes[0].set_title('Board 1 (Empty)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(b2_img, cmap='gray')\n",
    "axes[1].set_title('Board 2 (Missing Components)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(b3_img, cmap='gray')\n",
    "axes[2].set_title('Board 3 (Full)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(highlighted)\n",
    "axes[3].set_title('Differences Highlighted')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the images directly as grayscale\n",
    "board2_img = imread('b2_averaged_image.png')  # Replace with your image path\n",
    "board3_img = imread('b3_avg_aligned.png')  # Replace with your image path\n",
    "\n",
    "# Convert images to float for processing\n",
    "board2_img_float = board2_img.astype('float64')\n",
    "board3_img_float = board3_img.astype('float64')\n",
    "\n",
    "# Compute the absolute difference between the two images\n",
    "difference = np.abs(board3_img_float - board2_img_float)\n",
    "\n",
    "# Normalize the difference image to the range [0, 1] for display purposes\n",
    "difference_normalized = (difference - np.min(difference)) / (np.max(difference) - np.min(difference))\n",
    "\n",
    "# Apply a threshold to the normalized difference to highlight significant differences\n",
    "threshold_value = 0.1  # This can be adjusted based on your specific case\n",
    "difference_thresholded = difference_normalized > threshold_value\n",
    "\n",
    "# Prepare the highlighted image\n",
    "highlighted = np.zeros(board3_img.shape + (3,))\n",
    "highlighted[..., 0] = difference_thresholded  # Red channel\n",
    "highlighted[..., 1] = board3_img_float / np.max(board3_img_float)  # Green channel\n",
    "highlighted[..., 2] = board3_img_float / np.max(board3_img_float)  # Blue channel\n",
    "\n",
    "# Display the original images and the difference\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# axes[0].imshow(board2_img, cmap='gray')\n",
    "# axes[0].set_title('Board 2')\n",
    "# axes[0].axis('off')\n",
    "\n",
    "# axes[1].imshow(board3_img, cmap='gray')\n",
    "# axes[1].set_title('Board 3')\n",
    "# axes[1].axis('off')\n",
    "\n",
    "# Highlight the differences in red on the BOARD3 image\n",
    "axes[2].imshow(highlighted)\n",
    "axes[2].set_title('Differences Highlighted')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a969d3-c6ad-4add-a395-b0d532011bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fb64e-e0ca-4842-8cf6-b2cba9c03432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
